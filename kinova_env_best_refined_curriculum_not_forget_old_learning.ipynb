{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d2ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import numpy as np\n",
    "import time\n",
    "from collections import namedtuple\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94822d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class kinovaGen3Env(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(kinovaGen3Env, self).__init__()\n",
    "\n",
    "        # Connect to PyBullet\n",
    "        self.physics_client = p.connect(p.GUI)\n",
    "        p.setGravity(0, 0, -9.8)\n",
    "        p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "        # Set the simulation time step\n",
    "        p.setTimeStep(1 / 300)\n",
    "\n",
    "        # Action space: joint deltas (radians per step) for 6 joints\n",
    "        self.action_space = spaces.Box(\n",
    "            low=np.array([-0.05] * 6),\n",
    "            high=np.array([0.05] * 6),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # Observation space: [q(6), dq(6), eef_pos(3), goal - eef_pos(3)] = 18\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=-np.inf,\n",
    "            high=+np.inf,\n",
    "            shape=(6 + 6 + 3 + 3,),\n",
    "            dtype=np.float64\n",
    "        )\n",
    "\n",
    "        # Load environment objects\n",
    "        self.plane_id = p.loadURDF(\"plane.urdf\")\n",
    "        self.table_id = p.loadURDF(\n",
    "            \"table/table.urdf\",\n",
    "            [0.5, 0, 0],\n",
    "            p.getQuaternionFromEuler([0, 0, 0])\n",
    "        )\n",
    "        self.tray_id = p.loadURDF(\n",
    "            \"tray/tray.urdf\",\n",
    "            [0.5, 0.9, 0.6],\n",
    "            p.getQuaternionFromEuler([0, 0, 0])\n",
    "        )\n",
    "        self.cube_id2 = p.loadURDF(\n",
    "            \"cube.urdf\",\n",
    "            [0.5, 0.9, 0.3],\n",
    "            p.getQuaternionFromEuler([0, 0, 0]),\n",
    "            globalScaling=0.6,\n",
    "            useFixedBase=True\n",
    "        )\n",
    "\n",
    "        # Set GUI viewing angle\n",
    "        self.set_gui_view()\n",
    "\n",
    "        # Load the robot\n",
    "        self.robot = kinovaGen3([0, 0, 0.62], [0, 0, 0])\n",
    "        self.robot.load()\n",
    "\n",
    "        # Initialize cube\n",
    "        self.cube_id = None\n",
    "\n",
    "        # Episode/step settings\n",
    "        self.max_steps = 100\n",
    "        self.current_step = 0\n",
    "        self.gripper_range = [0, 0.085]  # [fully closed, fully open]\n",
    "\n",
    "        # Curriculum-related state\n",
    "        self.episode_idx = 0            # how many episodes have started\n",
    "        self.unlocked_stage = 0         # hardest stage unlocked so far (0..4)\n",
    "        self.curriculum_stage = 0       # stage used for the current episode\n",
    "        # thresholds in terms of episode index at which we unlock the next stage\n",
    "        # 0-49: max stage 0, 50-99: max stage 1, 100-149: max stage 2,\n",
    "        # 150-199: max stage 3, 200+: max stage 4\n",
    "        #self.curriculum_thresholds = [50, 300, 500, 700]\n",
    "        self.curriculum_thresholds = [0, 0, 0, 0]\n",
    "        # For action smoothness penalty\n",
    "        self.prev_action = np.zeros(6)\n",
    "\n",
    "    # ----------------- Curriculum helpers -----------------\n",
    "\n",
    "    def _update_unlocked_stage(self):\n",
    "        \"\"\"\n",
    "        Update self.unlocked_stage based on episode_idx and thresholds.\n",
    "        Stages:\n",
    "          0: y=0, x ~ center\n",
    "          1: y=0, x in lower region\n",
    "          2: y in [-0.3, 0], x in [0.4, 0.7]\n",
    "          3: y in [0, 0.3], x in [0.4, 0.7]\n",
    "          4: y in [-0.3, 0.3], x in [0.4, 0.7] (fully random in workspace)\n",
    "        \"\"\"\n",
    "        if self.episode_idx < self.curriculum_thresholds[0]:\n",
    "            self.unlocked_stage = 0\n",
    "        elif self.episode_idx < self.curriculum_thresholds[1]:\n",
    "            self.unlocked_stage = 1\n",
    "        elif self.episode_idx < self.curriculum_thresholds[2]:\n",
    "            self.unlocked_stage = 2\n",
    "        elif self.episode_idx < self.curriculum_thresholds[3]:\n",
    "            self.unlocked_stage = 3\n",
    "        else:\n",
    "            self.unlocked_stage = 4\n",
    "\n",
    "    def set_curriculum_stage(self, stage: int):\n",
    "        \"\"\"\n",
    "        Optional: manually override the curriculum stage for debugging/eval.\n",
    "        This forces the active stage for the next reset() call.\n",
    "        \"\"\"\n",
    "        self.unlocked_stage = int(stage)\n",
    "        self.curriculum_stage = int(stage)\n",
    "\n",
    "    # ----------------- Observation -----------------\n",
    "\n",
    "    def _obs(self):\n",
    "        q = np.array(\n",
    "            [p.getJointState(self.robot.id, j)[0]\n",
    "             for j in self.robot.arm_controllable_joints]\n",
    "        )\n",
    "        dq = np.array(\n",
    "            [p.getJointState(self.robot.id, j)[1]\n",
    "             for j in self.robot.arm_controllable_joints]\n",
    "        )\n",
    "        eef_pos = np.array(\n",
    "            p.getLinkState(self.robot.id, self.robot.eef_id)[4]\n",
    "        )  # worldLinkFramePosition\n",
    "        goal = self.target_pos\n",
    "        return np.concatenate([q, dq, eef_pos, goal - eef_pos], axis=0)\n",
    "\n",
    "    # ----------------- Visualization helpers -----------------\n",
    "\n",
    "    def set_gui_view(self):\n",
    "        \"\"\"\n",
    "        Set the GUI camera view (not actual camera capture)\n",
    "        \"\"\"\n",
    "        camera_distance = 1.1\n",
    "        camera_yaw = 90\n",
    "        camera_pitch = -45\n",
    "        camera_target = [0.5, 0, 0.6]  # Look-at point (center of table)\n",
    "\n",
    "        p.resetDebugVisualizerCamera(\n",
    "            cameraDistance=camera_distance,\n",
    "            cameraYaw=camera_yaw,\n",
    "            cameraPitch=camera_pitch,\n",
    "            cameraTargetPosition=camera_target\n",
    "        )\n",
    "\n",
    "    def draw_boundary(self, x_range, y_range, z_height):\n",
    "        \"\"\"\n",
    "        Draw a boundary box for the specified x and y ranges.\n",
    "        \"\"\"\n",
    "        corners = [\n",
    "            [x_range[0], y_range[0], z_height],  # Bottom-left\n",
    "            [x_range[1], y_range[0], z_height],  # Bottom-right\n",
    "            [x_range[1], y_range[1], z_height],  # Top-right\n",
    "            [x_range[0], y_range[1], z_height],  # Top-left\n",
    "        ]\n",
    "\n",
    "        for i in range(len(corners)):\n",
    "            p.addUserDebugLine(\n",
    "                corners[i],\n",
    "                corners[(i + 1) % len(corners)],\n",
    "                [1, 0, 0],\n",
    "                lineWidth=2\n",
    "            )\n",
    "\n",
    "    # ----------------- Reset -----------------\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"\n",
    "        Reset the environment.\n",
    "        Uses a probabilistic curriculum:\n",
    "          - Mostly samples from the hardest unlocked stage\n",
    "          - Sometimes samples from earlier stages (to avoid forgetting)\n",
    "        \"\"\"\n",
    "        # Gymnasium's seeding\n",
    "        if seed is not None:\n",
    "            super().reset(seed=seed)\n",
    "\n",
    "        self.current_step = 0\n",
    "        self.prev_action = np.zeros(6)\n",
    "\n",
    "        # Bookkeeping\n",
    "        self.episode_idx += 1\n",
    "        self._update_unlocked_stage()\n",
    "\n",
    "        # Sample the active curriculum stage for this episode\n",
    "        max_stage = self.unlocked_stage\n",
    "        if max_stage == 0:\n",
    "            stage_for_ep = 0\n",
    "        else:\n",
    "            # e.g. 70% of episodes use the hardest unlocked stage,\n",
    "            # 30% randomly sample an earlier stage [0, max_stage-1]\n",
    "            if np.random.rand() < 0.9:\n",
    "                stage_for_ep = max_stage\n",
    "            else:\n",
    "                stage_for_ep = np.random.randint(0, max_stage)\n",
    "\n",
    "        self.curriculum_stage = stage_for_ep\n",
    "\n",
    "        # Reset robot to a neutral pose\n",
    "        self.robot.orginal_position(self.robot)\n",
    "\n",
    "        # Workspace bounds\n",
    "        x_min, x_max = 0.4, 0.7\n",
    "        y_min, y_max = -0.3, 0.3\n",
    "\n",
    "        # Curriculum-based cube placement for this episode\n",
    "        if self.curriculum_stage == 0:\n",
    "            # Stage 0: cube near center, y = 0, x minimally varying\n",
    "            x = 0.55 + np.random.uniform(-0.02, 0.02)\n",
    "            x = float(np.clip(x, x_min, x_max))\n",
    "            y = 0.0\n",
    "\n",
    "        elif self.curriculum_stage == 1:\n",
    "            # Stage 1: move towards lower x at y = 0\n",
    "            x = np.random.uniform(0.4, 0.5)\n",
    "            y = 0.0\n",
    "\n",
    "        elif self.curriculum_stage == 2:\n",
    "            # Stage 2: random y in [-0.3, 0], x in [0.4, 0.7]\n",
    "            x = np.random.uniform(x_min, x_max)\n",
    "            y = np.random.uniform(-0.3, 0.0)\n",
    "\n",
    "        elif self.curriculum_stage == 3:\n",
    "            # Stage 3: random y in [0, 0.3], x in [0.4, 0.7]\n",
    "            x = np.random.uniform(x_min, x_max)\n",
    "            y = np.random.uniform(0.0, 0.3)\n",
    "\n",
    "        else:\n",
    "            # Stage 4: fully random in workspace y ∈ [-0.3, 0.3], x ∈ [0.4, 0.7]\n",
    "            x = np.random.uniform(x_min, x_max)\n",
    "            y = np.random.uniform(y_min, y_max)\n",
    "\n",
    "        cube_start_pos = [x, y, 0.63]\n",
    "\n",
    "        # Draw workspace boundary (purely visual)\n",
    "        self.draw_boundary([x_min, x_max], [y_min, y_max], 0.63)\n",
    "\n",
    "        cube_start_orn = p.getQuaternionFromEuler([0, 0, 0])\n",
    "        if self.cube_id:\n",
    "            p.resetBasePositionAndOrientation(\n",
    "                self.cube_id,\n",
    "                cube_start_pos,\n",
    "                cube_start_orn\n",
    "            )\n",
    "        else:\n",
    "            self.cube_id = p.loadURDF(\n",
    "                \"./urdf/cube_blue.urdf\",\n",
    "                cube_start_pos,\n",
    "                cube_start_orn\n",
    "            )\n",
    "\n",
    "        self.initial_cube_pos = np.array(cube_start_pos[:2])\n",
    "        self.target_pos = np.array([cube_start_pos[0], cube_start_pos[1], 1.0])\n",
    "\n",
    "        observation = self._obs()\n",
    "        info = {\n",
    "            \"curriculum_stage\": self.curriculum_stage,\n",
    "            \"unlocked_stage\": self.unlocked_stage,\n",
    "            \"episode_idx\": self.episode_idx,\n",
    "        }\n",
    "        return observation, info\n",
    "\n",
    "    # ----------------- Optional: gripper (unused for now) -----------------\n",
    "\n",
    "    def gripper_close(self):\n",
    "        grip_value = self.gripper_range[1]\n",
    "\n",
    "        while True:\n",
    "            contact_point = p.getContactPoints(bodyA=self.robot.id)\n",
    "\n",
    "            force = {}\n",
    "            if len(contact_point) > 0:\n",
    "                for i in contact_point:\n",
    "                    link_index = i[2]\n",
    "                    if force.get(link_index) is None:\n",
    "                        force[link_index] = {17: 0, 12: 0}\n",
    "                    if i[3] == 17:\n",
    "                        if i[9] > force[link_index][17]:\n",
    "                            force[link_index][17] = i[9]\n",
    "                    elif i[3] == 12:\n",
    "                        if i[9] > force[link_index][12]:\n",
    "                            force[link_index][12] = i[9]\n",
    "\n",
    "            for link_index in force:\n",
    "                if force[link_index][17] > 3 and force[link_index][12] > 3:\n",
    "                    print(f\"[Grasped] Link {link_index}: \"\n",
    "                          f\"joint 17 = {force[link_index][17]:.2f}, \"\n",
    "                          f\"joint 12 = {force[link_index][12]:.2f}\")\n",
    "                    return True\n",
    "\n",
    "            for link_index in force:\n",
    "                for joint in [17, 12]:\n",
    "                    if force[link_index][joint] > 0:\n",
    "                        print(f\"Link {link_index}, joint {joint} force: \"\n",
    "                              f\"{force[link_index][joint]:.2f}\")\n",
    "\n",
    "            if grip_value <= self.gripper_range[0]:\n",
    "                break\n",
    "\n",
    "            grip_value -= 0.001\n",
    "            self.robot.move_gripper(grip_value)\n",
    "\n",
    "            for _ in range(60):\n",
    "                p.stepSimulation()\n",
    "\n",
    "        return False\n",
    "\n",
    "    # ----------------- Step -----------------\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Perform an action in the environment.\n",
    "        Action: joint deltas (rad) for 6 joints.\n",
    "        \"\"\"\n",
    "        self.current_step += 1\n",
    "\n",
    "        # Current joint positions\n",
    "        q = np.array(\n",
    "            [p.getJointState(self.robot.id, j)[0]\n",
    "             for j in self.robot.arm_controllable_joints]\n",
    "        )\n",
    "\n",
    "        dq_cmd = action  # per-step delta (rad)\n",
    "        q_des = np.clip(q + dq_cmd,\n",
    "                        self.robot.lower_limits,\n",
    "                        self.robot.upper_limits)\n",
    "        self.robot.move_arm(q_des)\n",
    "\n",
    "        # Step simulation\n",
    "        for _ in range(100):\n",
    "            p.stepSimulation()\n",
    "\n",
    "        # EE pose and distance to target\n",
    "        eef_state = self.robot.get_current_ee_position()\n",
    "        eef_position = np.array(eef_state[0])[:3]\n",
    "        distance_to_target = float(np.linalg.norm(eef_position - self.target_pos))\n",
    "\n",
    "        collision_pts = self.robot.check_collision()\n",
    "\n",
    "        # --- Reward shaping params ---\n",
    "        ALPHA_DIST_FAR = 5.0\n",
    "        ALPHA_DIST_CLOSE = 1.0\n",
    "        DEADBAND = 0.05        # inside this, no distance penalty\n",
    "        COLLISION_PEN = 20.0\n",
    "        SUCCESS_THRESH = 0.02  # 2 cm\n",
    "        SUCCESS_BONUS = 100.0\n",
    "        TIME_BONUS_W = 1.0\n",
    "        BASE_SELF_CNT = 31\n",
    "\n",
    "        ACT_L2_W = 0.01\n",
    "        ACT_DELTA_W = 0.02\n",
    "\n",
    "        # --- Distance shaping ---\n",
    "        if distance_to_target > DEADBAND:\n",
    "            if distance_to_target > 0.05:\n",
    "                dist_penalty = -ALPHA_DIST_FAR * distance_to_target\n",
    "            else:\n",
    "                dist_penalty = -ALPHA_DIST_CLOSE * distance_to_target\n",
    "        else:\n",
    "            dist_penalty = 0.0\n",
    "\n",
    "        reward = dist_penalty\n",
    "\n",
    "        # --- Collision penalty (non-terminal) ---\n",
    "        meaningful_collisions = max(0, collision_pts - BASE_SELF_CNT)\n",
    "        if meaningful_collisions > 0:\n",
    "            reward -= COLLISION_PEN\n",
    "\n",
    "        # --- Limit proximity penalty ---\n",
    "        margin = 0.05\n",
    "        q_next = q + dq_cmd\n",
    "        dist_low = q_next - np.array(self.robot.lower_limits)\n",
    "        dist_high = np.array(self.robot.upper_limits) - q_next\n",
    "        violation_amount = np.sum(\n",
    "            np.clip(margin - dist_low, 0, margin) +\n",
    "            np.clip(margin - dist_high, 0, margin)\n",
    "        )\n",
    "        reward -= violation_amount * 1.0\n",
    "\n",
    "        # --- Action cost (smoothness) ---\n",
    "        if self.prev_action is not None:\n",
    "            act_l2 = float(np.mean(np.square(action)))\n",
    "            act_delta = float(np.mean(np.square(action - self.prev_action)))\n",
    "            reward -= ACT_L2_W * act_l2\n",
    "            reward -= ACT_DELTA_W * act_delta\n",
    "        self.prev_action = action.copy()\n",
    "\n",
    "        # --- Success / termination ---\n",
    "        done = False\n",
    "        truncated = False\n",
    "        is_successful = False\n",
    "\n",
    "        if distance_to_target <= SUCCESS_THRESH:\n",
    "            steps_left = max(0, self.max_steps - self.current_step)\n",
    "            reward += SUCCESS_BONUS + TIME_BONUS_W * steps_left\n",
    "            done = True\n",
    "            is_successful = True\n",
    "        elif self.current_step >= self.max_steps:\n",
    "            done = True\n",
    "            truncated = True\n",
    "            reward -= 10.0 * distance_to_target\n",
    "\n",
    "        print(f\"reward: {reward}\")\n",
    "        print(f\"Distance to target: {distance_to_target}\")\n",
    "        observation = self._obs()\n",
    "        info = {\n",
    "            \"curriculum_stage\": self.curriculum_stage,\n",
    "            \"unlocked_stage\": self.unlocked_stage,\n",
    "            \"episode_idx\": self.episode_idx,\n",
    "            \"is_successful\": is_successful,\n",
    "        }\n",
    "\n",
    "        return observation, reward, done, truncated, info\n",
    "\n",
    "    # ----------------- Extra helpers -----------------\n",
    "\n",
    "    def lift_object_slowly(self, start_pos, end_z, eef_orientation,\n",
    "                            steps=30, sim_steps_per_move=5, sleep_time=0.005):\n",
    "        \"\"\"\n",
    "        Smooth lifting sequence (unused for RL right now).\n",
    "        \"\"\"\n",
    "        for i in range(steps):\n",
    "            intermediate_z = start_pos[2] + (end_z - start_pos[2]) * (i + 1) / steps\n",
    "            lift_pos = np.array([start_pos[0], start_pos[1], intermediate_z])\n",
    "            self.robot.move_arm_ik(lift_pos, eef_orientation)\n",
    "\n",
    "            for _ in range(sim_steps_per_move):\n",
    "                p.stepSimulation()\n",
    "                if sleep_time > 0:\n",
    "                    time.sleep(sleep_time)\n",
    "\n",
    "    def close(self):\n",
    "        p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada9cf3a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class kinovaGen3:\n",
    "    def __init__(self, pos, ori):\n",
    "        self.base_pos = pos\n",
    "        self.base_ori = p.getQuaternionFromEuler(ori)\n",
    "        self.eef_id = 7\n",
    "        self.arm_num_dofs = 6\n",
    "        self.arm_rest_poses = [-1.57, -1.54, 1.34, -1.37, -1.57, 0.0]\n",
    "        self.gripper_range = [0, 0.085]\n",
    "        self.max_velocity = 2\n",
    "\n",
    "        # Hard-coded joint limits for 6 DOF arm (must match URDF)\n",
    "        self.lower_limits = np.array([-2.69, -2.69, -2.69, -2.59, -2.57, -2.59])\n",
    "        self.upper_limits = np.array([ 2.69,  2.69,  2.69,  2.59,  2.57,  2.59])\n",
    "\n",
    "    def load(self):\n",
    "        self.id = p.loadURDF(\n",
    "            './urdf/gen3_lite.urdf',\n",
    "            self.base_pos,\n",
    "            self.base_ori,\n",
    "            useFixedBase=True\n",
    "        )\n",
    "        self.__parse_joint_info__()\n",
    "        self.__setup_mimic_joints__()\n",
    "\n",
    "    def __parse_joint_info__(self):\n",
    "        jointInfo = namedtuple(\n",
    "            'jointInfo',\n",
    "            ['id', 'name', 'type', 'lowerLimit', 'upperLimit',\n",
    "             'maxForce', 'maxVelocity', 'controllable']\n",
    "        )\n",
    "        self.joints = []\n",
    "        self.controllable_joints = []\n",
    "\n",
    "        for i in range(p.getNumJoints(self.id)):\n",
    "            info = p.getJointInfo(self.id, i)\n",
    "            jointID = info[0]\n",
    "            jointName = info[1].decode(\"utf-8\")\n",
    "            jointType = info[2]\n",
    "            jointLowerLimit = info[8]\n",
    "            jointUpperLimit = info[9]\n",
    "            jointMaxForce = info[10]\n",
    "            jointMaxVelocity = info[11]\n",
    "            controllable = jointType != p.JOINT_FIXED\n",
    "            if controllable:\n",
    "                self.controllable_joints.append(jointID)\n",
    "            self.joints.append(\n",
    "                jointInfo(\n",
    "                    jointID, jointName, jointType,\n",
    "                    jointLowerLimit, jointUpperLimit,\n",
    "                    jointMaxForce, jointMaxVelocity,\n",
    "                    controllable\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.arm_controllable_joints = self.controllable_joints[:self.arm_num_dofs]\n",
    "        self.arm_lower_limits = [j.lowerLimit for j in self.joints if j.controllable][:self.arm_num_dofs]\n",
    "        self.arm_upper_limits = [j.upperLimit for j in self.joints if j.controllable][:self.arm_num_dofs]\n",
    "        self.arm_joint_ranges = [\n",
    "            ul - ll for ul, ll in zip(self.arm_upper_limits, self.arm_lower_limits)\n",
    "        ]\n",
    "\n",
    "    def __setup_mimic_joints__(self):\n",
    "        mimic_parent_name = 'right_finger_bottom_joint'\n",
    "        mimic_children_names = {\n",
    "            'right_finger_tip_joint': -0.676,\n",
    "            'left_finger_bottom_joint': 1,\n",
    "            'left_finger_tip_joint': -0.676\n",
    "        }\n",
    "        self.mimic_parent_id = [\n",
    "            joint.id for joint in self.joints if joint.name == mimic_parent_name\n",
    "        ][0]\n",
    "        self.mimic_child_multiplier = {\n",
    "            joint.id: mimic_children_names[joint.name]\n",
    "            for joint in self.joints if joint.name in mimic_children_names\n",
    "        }\n",
    "\n",
    "        for joint_id, multiplier in self.mimic_child_multiplier.items():\n",
    "            c = p.createConstraint(\n",
    "                self.id, self.mimic_parent_id,\n",
    "                self.id, joint_id,\n",
    "                jointType=p.JOINT_GEAR,\n",
    "                jointAxis=[0, 1, 0],\n",
    "                parentFramePosition=[0, 0, 0],\n",
    "                childFramePosition=[0, 0, 0]\n",
    "            )\n",
    "            p.changeConstraint(\n",
    "                c, gearRatio=-multiplier, maxForce=100, erp=1\n",
    "            )\n",
    "\n",
    "    def check_collision(self):\n",
    "        pts = p.getClosestPoints(\n",
    "            bodyA=self.id,\n",
    "            bodyB=self.id,\n",
    "            distance=0.0\n",
    "        )\n",
    "        print(len(pts))\n",
    "        return len(pts)\n",
    "\n",
    "    def move_gripper(self, open_length):\n",
    "        open_length = max(self.gripper_range[0],\n",
    "                          min(open_length, self.gripper_range[1]))\n",
    "        open_angle = 0.715 - math.asin((open_length - 0.010) / 0.1143)\n",
    "        p.setJointMotorControl2(\n",
    "            self.id,\n",
    "            self.mimic_parent_id,\n",
    "            p.POSITION_CONTROL,\n",
    "            targetPosition=open_angle,\n",
    "            force=50,\n",
    "            maxVelocity=self.joints[self.mimic_parent_id].maxVelocity\n",
    "        )\n",
    "\n",
    "    def move_arm_ik(self, target_pos, target_orn):\n",
    "        joint_poses = p.calculateInverseKinematics(\n",
    "            self.id, self.eef_id, target_pos, target_orn,\n",
    "            lowerLimits=self.arm_lower_limits,\n",
    "            upperLimits=self.arm_upper_limits,\n",
    "            jointRanges=self.arm_joint_ranges,\n",
    "            restPoses=self.arm_rest_poses,\n",
    "        )\n",
    "        for i, joint_id in enumerate(self.arm_controllable_joints):\n",
    "            p.setJointMotorControl2(\n",
    "                self.id,\n",
    "                joint_id,\n",
    "                p.POSITION_CONTROL,\n",
    "                joint_poses[i],\n",
    "                maxVelocity=self.max_velocity\n",
    "            )\n",
    "\n",
    "    def move_arm(self, target_pos):\n",
    "        for i, joint_id in enumerate(self.arm_controllable_joints):\n",
    "            p.setJointMotorControl2(\n",
    "                self.id,\n",
    "                joint_id,\n",
    "                p.POSITION_CONTROL,\n",
    "                target_pos[i],\n",
    "                maxVelocity=self.max_velocity\n",
    "            )\n",
    "\n",
    "    def get_current_ee_position(self):\n",
    "        return p.getLinkState(self.id, self.eef_id)\n",
    "\n",
    "    def orginal_position(self, robot):\n",
    "        target_joint_positions = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "        for i, joint_id in enumerate(robot.arm_controllable_joints):\n",
    "            p.setJointMotorControl2(\n",
    "                robot.id,\n",
    "                joint_id,\n",
    "                p.POSITION_CONTROL,\n",
    "                target_joint_positions[i]\n",
    "            )\n",
    "        for _ in range(100):\n",
    "            p.stepSimulation()\n",
    "        self.move_gripper(0.085)\n",
    "        for _ in range(3500):\n",
    "            p.stepSimulation()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
